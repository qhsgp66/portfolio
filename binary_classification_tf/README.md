# 딥러닝 이진 분류

리뷰 데이터를 긍정과 부정으로 분류하는 딥러닝 프로젝트이다.

### 프로젝트 기획
(1) 리뷰데이터를 별점에 따라 긍정과 부정 데이터로 나눈다.

(2) LSTM을 기반으로 딥러닝 모델을 구현한다.

(3) 식당 리뷰는 긍정 리뷰가 압도적으로 많은 불균형 데이터이다.
따라서 불균형 데이터와 다운샘플링 한 균형 데이터를 각각 학습하여 예측 성능을 비교해보자.

가설 : 다운샘플링을 사용하여 불균형 데이터를 해결하면 모델의 성능이 향상될 것이다.


### 데이터 전처리
식당리뷰 데이터의 특성을 고려하여 데이터 전처리 수행한다.
- '좋아요', '맛있어요' 등의 중복리뷰를 제거하기 위해 5자 이상의 리뷰만 선정한다.

- 식당 리뷰의 별점은 4.5점, 5점에 쏠려있으므로 4점 이상은 긍정, 3.5점 이하는 부정 리뷰로 분류한다.

- 맞춤법을 거의 지키지 않는 리뷰가 많으므로 글자 단위로 토큰화를 실행한다.

### 딥러닝 모델 구조
```
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       (None, 125, 16)           29280     
                                                                 
 lstm (LSTM)                 (None, 125, 16)           2112      
                                                                 
 flatten (Flatten)           (None, 2000)              0         
                                                                 
 dropout (Dropout)           (None, 2000)              0         
                                                                 
 dense (Dense)               (None, 1)                 2001      
                                                                 
=================================================================
Total params: 33,393
Trainable params: 33,393
Non-trainable params: 0
_________________________________________________________________
```
### 불균형 데이터 처리
불균형 데이터를 처리하기 위해 다운샘플링을 실시한다.

다운샘플링 전과 후의 데이터 수 : 41803 / 10380

### 모델 성능 비교
불균형 데이터를 가진 모델의 성능을 불균형 데이터에 비교적 적합한 auc_metric로 비교한다.

데이터 수 : 41803 / 10380  
불균형 데이터 : loss: 0.2200 - accuracy: 0.9170 - auc: 0.9047  
균형 데이터   : loss: 0.4242 - accuracy: 0.8054 - auc: 0.8880  

### 결과  
- 다운샘플링을 하기 전의 모델이 loss, accuracy, AUC 측면에서 더 나은 결과를 보였기 때문에   
다운샘플링이 불균형 데이터를 해결하는 데 있어 모델 성능을 향상시킬 것이라는 가설은 기각되었다.   

- 데이터 크기의 현저한 감소는 가설을 기각하는 이유 중 하나로 간주될 수 있다.  
따라서 다운샘플링보다는 데이터의 양이 줄어들지 않는 업샘플링을 시도하는 것이 모델의 성능 향상을 기대할 수 있다.  
