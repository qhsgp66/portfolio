# 딥러닝 이진 분류

리뷰 데이터를 긍정과 부정으로 분류하는 딥러닝 프로젝트이다.

### 프로젝트 기획
(1) 리뷰데이터를 별점에 따라 긍정과 부정 데이터로 나눈다.

(2)  데이터이므로 LSTM을 기반으로 딥러닝 모델을 구현한다.

(3) 식당 리뷰는 긍정 리뷰가 압도적으로 많은 불균형 데이터이다.  
따라서 불균형 데이터와 균형 데이터(언더샘플링, 오버샘플링)를 각각 학습하여 예측 성능을 비교해보자.

### 가설 설정  

가설1 : 균형 데이터 모델이 불균형 데이터 모델보다 더 좋은 성능을 보일 것이다.  

가설2 : 균형 데이터 모델 중에서는 오버샘플링 모델이 언더샘플링 모델보다 더 좋은 성능을 보일 것이다.  

(accuracy : 오버샘플링 > 언더샘플링 > 불균형데이터)


### 데이터 전처리
식당리뷰 데이터의 특성을 고려하여 데이터 전처리 수행한다.
- '좋아요', '맛있어요' 등의 중복리뷰를 제거하기 위해 5자 이상의 리뷰만 선정한다.

- 식당 리뷰의 별점은 4.5점, 5점에 쏠려있으므로 4점 이상은 긍정, 3.5점 이하는 부정 리뷰로 분류한다.

- 맞춤법을 거의 지키지 않는 리뷰가 많으므로 글자 단위로 토큰화를 실행한다.  

- train : val = 8:2로 데이터를 분리한다.  

- 불균형 데이터를 처리하기 위해 언더샘플링과 오버샘플링을 실시하였다.   
  -언더샘플링은 Random Sampling 방법을, 오버샘플링은 Resampling 방법을 사용하였다.

### 딥러닝 모델 구조
```
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       (None, 125, 16)           29280     
                                                                 
 lstm (LSTM)                 (None, 125, 16)           2112      
                                                                 
 flatten (Flatten)           (None, 2000)              0         
                                                                 
 dropout (Dropout)           (None, 2000)              0         
                                                                 
 dense (Dense)               (None, 1)                 2001      
                                                                 
=================================================================
Total params: 33,393
Trainable params: 33,393
Non-trainable params: 0
_________________________________________________________________
```


### 모델 성능 비교
||불균형데이터|언더샘플링|오버샘플링|
|:----:|:----:|:----:|:----:|
|학습데이터 수|41803|8404|58480|
|loss|**0.2311**|0.3565|0.3196|
|accuracy|**0.9183**|0.8643|0.8743|  

### 결과  
- 불균형 데이터로 학습시킨 모델이 균형 데이터로 학습시킨 모델보다 더 좋은 성능을 보였다.
- 균형 데이터 모델 중에서는 오버샘플링 모델이 언더샘플링 모델 보다 더 좋은 성능을 보였다.
- 즉, 가설1은 기각되었고, 가설2는 기각되지 않았다.
- 가설 1이 기각된 이유는 샘플링 전에 데이터를 분리하여 검증용 데이터의 majority_class와 minority_class의 비율이 불균형 데이터 모델과 동일하기 때문이다.  
- 가설 2가 기각되지 않은 원인은 학습 데이터 수의 차이로 추측해 볼 수 있다.   


